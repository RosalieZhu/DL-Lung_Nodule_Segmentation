{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test Split and Dissection of Scans to Patchs.\n",
    "1. Performs the train, validation and test split of the lung-segmented scans and their corresponding ground truth nodule-mask scans. The split is done by reading the SeriesInstanceUIDs of all scans and randomizing them into three categories at a 8:1:1 ratio. The randomization is done at the scan level rather than the image/slice level.\n",
    "\n",
    "2. Dissect the 3D scans into 2D images.\n",
    "\n",
    "**Authors**: Chen \"Raphael\" Liu and Nanyan \"Rosalie\" Zhu, *Columbia University*\n",
    "\n",
    "**Date**: April 27, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define environmental variables and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob as glob\n",
    "import re\n",
    "import random\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "%matplotlib inline\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of all the files we need.\n",
    "**There are two datasets we worked with.**\n",
    "1. LUNA16 dataset.\n",
    "    - This is what we use to generate the inputs to the deep learning models.\n",
    "2. LIDC-IDRI dataset.\n",
    "    - This is the parent dataset of LUNA16 (everthing in LUNA16 came from LIDC).\n",
    "    - We found the voxel-level annotations on this dataset given by radiologists (from which we generated the ground truth scans). Therefore some ground truth scans are not corresponding to anything in LUNA16 dataset.\n",
    "\n",
    "**We have these files available, either gathered online or generated by our preprocessing steps.**\n",
    "1. LUNA16 raw scans.\n",
    "    - Type: *.mhd and *.raw.\n",
    "    - Quantity: 888.\n",
    "    - Content: unprocessed 3D CT lung scans from LUNA16 dataset.\n",
    "    - Location: /home/raphael/Projects/DL-Lung_Nodule_LUNA16/Datasets/LUNA16_dataset/scans_all\n",
    "2. Preprocessed scans.\n",
    "    - Type: *.dcm.\n",
    "    - Quantity: ongoing, should be 888 by completion.\n",
    "    - Content: thresholded and contrast-enhanced 3D CT lung scans from LUNA16 dataset.\n",
    "    - Location: /home/raphael/Projects/DL-Lung_Nodule_LUNA16/Solutions/LungAndNoduleMasks/3DLungMasks/Preprocessed\n",
    "3. Lung-segmented scans.\n",
    "    - Type: *.dcm\n",
    "    - Quantity: ongoing, should be 888 by completion.\n",
    "    - Content: lung-segmented 3D CT lung scans from LUNA16 dataset.\n",
    "    - Location: /home/raphael/Projects/DL-Lung_Nodule_LUNA16/Solutions/LungAndNoduleMasks/3DLungMasks/Segmented\n",
    "4. Ground truth scans.\n",
    "    - Type: *.dcm\n",
    "    - Quantity: 3544 (886 scans, each annotated by 4 radiologists). Note that the number of scans annotated is smaller than the total number of LIDC files and maybe smaller than the size of LUNA16 dataset of 888 because some patients may not have a nodule at all.\n",
    "    - Content: binary voxel-level 3D masks representing whether or not each voxel belongs to a nodule, from the LIDC dataset.\n",
    "    - Location: home/raphael/Projects/DL-Lung_Nodule_LUNA16/Solutions/LungAndNoduleMasks/3DNoduleMasks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scans_path = '/home/raphael/Projects/DL-Lung_Nodule_LUNA16/Datasets/LUNA16_dataset/scans_all'\n",
    "preprocessed_scans_path = '/home/raphael/Projects/DL-Lung_Nodule_LUNA16/Solutions/LungAndNoduleMasks/3DLungMasks/Preprocessed'\n",
    "lung_segmented_scans_path = '/home/raphael/Projects/DL-Lung_Nodule_LUNA16/Solutions/LungAndNoduleMasks/3DLungMasks/Segmented'\n",
    "ground_truth_scans_path = '/home/raphael/Projects/DL-Lung_Nodule_LUNA16/Solutions/LungAndNoduleMasks/3DNoduleMasks'\n",
    "modified_LUNA16_annotation_path = '/home/raphael/Projects/DL-Lung_Nodule_LUNA16/Datasets/LUNA_annotation/annotation_in_scan.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all SeriesInstanceUIDs and perform train, validation, test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file names of the LUNA16 raw scans. They will be in the form of 'directory/SeriesUID.dcm'.\n",
    "raw_scans_filenames = glob(raw_scans_path + '/*.mhd')\n",
    "\n",
    "# Construct a list of SeriesInstanceUIDs.\n",
    "SeriesInstanceUIDs = []\n",
    "for current_filename in raw_scans_filenames:\n",
    "    current_SeriesInstanceUID_with_extension = re.split('/', current_filename)[-1]\n",
    "    current_SeriesInstanceUID = current_SeriesInstanceUID_with_extension[0:-4]\n",
    "    SeriesInstanceUIDs.append(current_SeriesInstanceUID)\n",
    "\n",
    "# Check the length of the list. Should be 888.\n",
    "len(SeriesInstanceUIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed to make the randomization replicable.\n",
    "random.seed(20190427)\n",
    "\n",
    "# Perform train, validation and test split on these SeriesInstanceUIDs.\n",
    "# Define the splitting ratio. Here we use 8:1:1.\n",
    "train_sample_fraction = 0.8\n",
    "validation_sample_fraction = 0.1\n",
    "\n",
    "# First randomly sample indices for the train set.\n",
    "index_pool_available = range(len(SeriesInstanceUIDs))\n",
    "train_sample_size = round(len(SeriesInstanceUIDs)*train_sample_fraction)\n",
    "train_indices = random.sample(index_pool_available, train_sample_size)\n",
    "\n",
    "# Then randomly sample indices for the validation set.\n",
    "index_pool_available = list(set(index_pool_available) - set(train_indices))\n",
    "validation_sample_size = round(len(SeriesInstanceUIDs)*validation_sample_fraction)\n",
    "validation_indices = random.sample(index_pool_available, validation_sample_size)\n",
    "\n",
    "# The remaining indices are assigned to the test set.\n",
    "test_indices = list(set(index_pool_available) - set(validation_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(710, 89, 89)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of each set.\n",
    "len(train_indices), len(validation_indices), len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the SeriesInstanceUIDs.\n",
    "SeriesInstanceUIDs_train = [SeriesInstanceUIDs[index] for index in train_indices]\n",
    "SeriesInstanceUIDs_validation = [SeriesInstanceUIDs[index] for index in validation_indices]\n",
    "SeriesInstanceUIDs_test = [SeriesInstanceUIDs[index] for index in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read our modified LUNA16 annotation spreadsheet (x, y, z, r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seriesuid</th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "      <th>diameter_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>29</td>\n",
       "      <td>136</td>\n",
       "      <td>140</td>\n",
       "      <td>5.651471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>261</td>\n",
       "      <td>100</td>\n",
       "      <td>211</td>\n",
       "      <td>4.224708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...</td>\n",
       "      <td>240</td>\n",
       "      <td>169</td>\n",
       "      <td>160</td>\n",
       "      <td>5.786348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n",
       "      <td>96</td>\n",
       "      <td>183</td>\n",
       "      <td>266</td>\n",
       "      <td>8.143262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n",
       "      <td>122</td>\n",
       "      <td>163</td>\n",
       "      <td>252</td>\n",
       "      <td>18.545150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           seriesuid  coordX  coordY  coordZ  \\\n",
       "0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...      29     136     140   \n",
       "1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...     261     100     211   \n",
       "2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...     240     169     160   \n",
       "3  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...      96     183     266   \n",
       "4  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...     122     163     252   \n",
       "\n",
       "   diameter_mm  \n",
       "0     5.651471  \n",
       "1     4.224708  \n",
       "2     5.786348  \n",
       "3     8.143262  \n",
       "4    18.545150  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the resized annotation.csv (the coordinates are resized to match the dimensions of the preprocessing and lung-segmetation result)\n",
    "modified_LUNA16_annotation = pd.read_csv(modified_LUNA16_annotation_path)\n",
    "modified_LUNA16_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diameter = list(np.asarray((modified_LUNA16_annotation))[:,4])\n",
    "fig = plt.figure(1)\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "ax = fig.add_subplot(111)\n",
    "#ax.set_title('Histogram of LUNA16 Nodule Diameter')\n",
    "plt.hist(diameter, histtype = 'step');\n",
    "ax.set_xlabel('Diameter (mm)')\n",
    "ax.set_ylabel('Number of Nodules')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the LUNA16 annotation and create a dictionary of horizontal slices to use.\n",
    "- We will only include horizontal slices that contain one and only one nodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_LUNA16_annotation = dict.fromkeys(list(np.array(modified_LUNA16_annotation.seriesuid)))\n",
    "for SeriesInstanceUID in list(clean_LUNA16_annotation.keys()):\n",
    "    # Extract a small dataframe that only contains the current scan.\n",
    "    nodules_in_this_scan = modified_LUNA16_annotation[modified_LUNA16_annotation['seriesuid'] == SeriesInstanceUID]\n",
    "    # Extract the (z, r) information of the nodules in the current scan.\n",
    "    nodule_z = np.array(nodules_in_this_scan['coordZ'])\n",
    "    nodule_r = np.array(nodules_in_this_scan['diameter_mm'])\n",
    "    # Create a list to store all the possible z values where at least one nodule exists.\n",
    "    z_list = []\n",
    "    # For every z value covered by every nodule, add that to the list. That is to say,\n",
    "    # if a horizontal slice contains 3 nodules, that slice index (z value) will show up 3 times in this list.\n",
    "    for i in range(len(nodule_z)):\n",
    "        nodule_range = list(range(int(nodule_z[i]-np.ceil(nodule_r[i])), int(nodule_z[i] + np.ceil(nodule_r[i]) + 1)))\n",
    "        z_list += nodule_range\n",
    "    # Create a list to store the unique z values.\n",
    "    unique_z_list = np.unique(z_list)\n",
    "    # Check the z list and unique z list and determine the bad slices (slices that contain more than 1 nodules).\n",
    "    bad_slices = []\n",
    "    for unique_z in unique_z_list:\n",
    "        if sum(z_list == unique_z) > 1:\n",
    "            bad_slices.append(unique_z)\n",
    "    # The set difference of the unique list and bad slices is the list of good slices.\n",
    "    good_slices = list(set(unique_z_list) - set(bad_slices))    \n",
    "    # The slice (z value) indices of these good slices in the current scan are the dictionary \"values\"\n",
    "    # that correspond to the dictionary \"key\" of the current SeriesInstanceUID.\n",
    "    clean_LUNA16_annotation[str(SeriesInstanceUID)] = np.sort(good_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within each set, load the 3D ground truth scans, preprocessed scans, and lung-segmented scans. Process them into patchs.\n",
    "- Step 1: Four 3D ground truth scans to one 3D ground truth scan.\n",
    "    - For each 3D raw CT lung scan where one or more nodules exist, there are 4 corresponding 3D ground truth scans interpolated from the annotations of 4 different radiologists.\n",
    "    - Here we use the following rule to generate one ground truth scan per raw scan:\n",
    "        For every voxel, it has to be annotated by at least 3 radiologists to be considered as part of a nodule.\n",
    "- Step 2: One 3D ground truth scan to 2D patchs.\n",
    "    - Disassemble the 3D scan along the z-axis and generate 2D patchs.\n",
    "    - Only save the images with nodules according to our cleaned-up LUNA16 annotation.\n",
    "    - Crop the patchs around the LUNA16-annotated x- and y- coordinates of the nodules.\n",
    "    - Generate some negative patches that won't necessarily contain nodules as well.\n",
    "   \n",
    "**Note**: Here we define three hyperparameters.\n",
    "1. *majority_voting_threshold*: For each voxel, we will consider that as part of a nodule if more than *majority_voting_threshold* radiologists annotated that voxel.\n",
    "2. *augmentation_rate*: For each valid (x, y, z) LUNA16-claimed nodule center, we will generate *augmentation_rate* image-augmented (through affine translation) patches.\n",
    "3. *negative_patch_ratio*: After generating these positive patches that are \"guaranteed\" to contain nodules (suppose there are N such patches), we will also generate N $\\times$ *negative_patch_ratio* negative patches. The so-called \"negative patches\" is a misnomer, in that they are generated randomly in the same scan, but we called them \"negative patches\" instead of \"random patches\" to distinguish them from the positive patches.\n",
    "\n",
    "All these patches are 2D horizontal images of dimension 32 $\\times$ 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_voting_threshold = 1 # We need more than 1 radiologist to confirm.\n",
    "augmentation_rate = 5 # 5 patches on one single claimed (x, y, z) nodule center.\n",
    "negative_patch_ratio = 0.25 # This will result in an overall positve-negative ratio of 80 % to 20 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './dataset/Patches_with_nodules-' + '%d-%d-%.4f'%(majority_voting_threshold, augmentation_rate, negative_patch_ratio)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "if not os.path.exists(os.path.join(save_path, 'train')):\n",
    "    os.makedirs(os.path.join(save_path, 'train'))\n",
    "if not os.path.exists(os.path.join(save_path, 'train_GT')):\n",
    "    os.makedirs(os.path.join(save_path, 'train_GT'))\n",
    "if not os.path.exists(os.path.join(save_path, 'train_PP')):\n",
    "    os.makedirs(os.path.join(save_path, 'train_PP'))\n",
    "if not os.path.exists(os.path.join(save_path, 'valid')):\n",
    "    os.makedirs(os.path.join(save_path, 'valid'))\n",
    "if not os.path.exists(os.path.join(save_path, 'valid_GT')):\n",
    "    os.makedirs(os.path.join(save_path, 'valid_GT'))\n",
    "if not os.path.exists(os.path.join(save_path, 'valid_PP')):\n",
    "    os.makedirs(os.path.join(save_path, 'valid_PP'))\n",
    "if not os.path.exists(os.path.join(save_path, 'test')):\n",
    "    os.makedirs(os.path.join(save_path, 'test'))\n",
    "if not os.path.exists(os.path.join(save_path, 'test_GT')):\n",
    "    os.makedirs(os.path.join(save_path, 'test_GT'))\n",
    "if not os.path.exists(os.path.join(save_path, 'test_PP')):\n",
    "    os.makedirs(os.path.join(save_path, 'test_PP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters (in Hounsfield units) for the intensity transform. This depends on how we originally windowed these scans.\n",
    "window_center = -600\n",
    "window_width = 1500\n",
    "lower_threshold = -800\n",
    "HU_lowerbound = max(window_center - 1/2*window_width, lower_threshold)\n",
    "HU_upperbound = window_center + 1/2*window_width\n",
    "\n",
    "# Define a list to store the SeriesInstanceUIDs of scans that didn't successfully go through the following process.\n",
    "bad_scans = []\n",
    "\n",
    "# Prepare the train, validation and test sets.\n",
    "for set_being_prepared in ['train', 'valid', 'test']:\n",
    "    if set_being_prepared == 'train':\n",
    "        SeriesInstanceUIDs_current_set = SeriesInstanceUIDs_train\n",
    "    elif set_being_prepared == 'valid':\n",
    "        SeriesInstanceUIDs_current_set = SeriesInstanceUIDs_validation\n",
    "    else:\n",
    "        SeriesInstanceUIDs_current_set = SeriesInstanceUIDs_test\n",
    "    \n",
    "    # Iterate through SeriesInstanceUIDs corresponding to the current set.\n",
    "    for SeriesInstanceUID in SeriesInstanceUIDs_current_set:\n",
    "        try:\n",
    "            ###################### preprocessed scan ############################\n",
    "            # Grab the preprocessed scan.\n",
    "            preprocessed_filenames = glob(preprocessed_scans_path + '/' + SeriesInstanceUID + '_preprocessed.dcm')\n",
    "            # Load the DICOM objects.\n",
    "            PP_scan_obj = pydicom.dcmread(preprocessed_filenames[0])\n",
    "            # Extract the DICOM data.\n",
    "            PP_scan = PP_scan_obj.pixel_array\n",
    "            # Convert the preprocessed scan to double precision between 0 and 1.\n",
    "            PP_scan = np.double((PP_scan - HU_lowerbound)/(HU_upperbound-HU_lowerbound))\n",
    "            ###################### lung-segmented scan ##########################\n",
    "            # Grab the lung-segmented scan.\n",
    "            lung_segmented_filenames = glob(lung_segmented_scans_path + '/' + SeriesInstanceUID + '_segmented.dcm')\n",
    "            # Load the DICOM objects.\n",
    "            LS_scan_obj = pydicom.dcmread(lung_segmented_filenames[0])\n",
    "            # Extract the DICOM data.\n",
    "            LS_scan = LS_scan_obj.pixel_array\n",
    "            # Convert the lung-segmented scan to double precision between 0 and 1.\n",
    "            LS_scan = np.double((LS_scan - HU_lowerbound)/(HU_upperbound-HU_lowerbound))\n",
    "            ############################## GT scan ############################## \n",
    "            # Grab the 4 ground truth scans using the SeriesInstanceUID.\n",
    "            ground_truth_filenames = glob(ground_truth_scans_path + '/' + SeriesInstanceUID + '*.dcm')\n",
    "            # Load the DICOM objects.\n",
    "            GT1_scan_obj = pydicom.dcmread(ground_truth_filenames[0])\n",
    "            GT2_scan_obj = pydicom.dcmread(ground_truth_filenames[1])\n",
    "            GT3_scan_obj = pydicom.dcmread(ground_truth_filenames[2])\n",
    "            GT4_scan_obj = pydicom.dcmread(ground_truth_filenames[3])    \n",
    "            # Extract the DICOM data.\n",
    "            GT1_scan = GT1_scan_obj.pixel_array\n",
    "            GT2_scan = GT2_scan_obj.pixel_array\n",
    "            GT3_scan = GT3_scan_obj.pixel_array\n",
    "            GT4_scan = GT4_scan_obj.pixel_array\n",
    "            # Form the one and only ground truth scan using our rule.\n",
    "            GT_scan = np.double(GT1_scan + GT2_scan + GT3_scan + GT4_scan > majority_voting_threshold)\n",
    "            # Read the cleaned-up LUNA16 annotation to find the slice indices where one and only one nodule exists.\n",
    "            candidate_slices_list = list(clean_LUNA16_annotation[str(SeriesInstanceUID)])\n",
    "            # Extract the dataframe of all nodules in this scan.\n",
    "            nodules_in_this_scan = modified_LUNA16_annotation[modified_LUNA16_annotation['seriesuid'] == SeriesInstanceUID]\n",
    "            # Extract the (x, y, z, r) information of all these nodules.\n",
    "            nodule_x = np.asarray(nodules_in_this_scan['coordX'])\n",
    "            nodule_y = np.asarray(nodules_in_this_scan['coordY'])\n",
    "            nodule_z = np.asarray(nodules_in_this_scan['coordZ'])\n",
    "            nodule_r = np.asarray(nodules_in_this_scan['diameter_mm']/2)\n",
    "            # Find the (x, y, z) that we need to locate the patchs.\n",
    "            for i in range(len(nodule_z)):\n",
    "                mask = np.logical_and((nodule_z[i]-nodule_r[i]) < clean_LUNA16_annotation[SeriesInstanceUID], clean_LUNA16_annotation[SeriesInstanceUID] < (nodule_z[i] + nodule_r[i]))\n",
    "                for slice_idx in clean_LUNA16_annotation[SeriesInstanceUID] [clean_LUNA16_annotation[SeriesInstanceUID] * mask != 0]:\n",
    "                    for patch_idx in range(augmentation_rate):\n",
    "                        # Apply image augmentation using affine translation.\n",
    "                        x_shift = random.randint(-16, 16)\n",
    "                        y_shift = random.randint(-16, 16)\n",
    "                        \n",
    "                        GT_patch = GT_scan[slice_idx, round(nodule_x[i] - 16) + x_shift : round(nodule_x[i] + 16) + x_shift,\\\n",
    "                                           round(nodule_y[i] - 16) + y_shift : round(nodule_y[i] + 16) + y_shift]\n",
    "                        PP_patch = PP_scan[slice_idx, round(nodule_x[i] - 16) + x_shift : round(nodule_x[i] + 16) + x_shift,\\\n",
    "                                           round(nodule_y[i] - 16) + y_shift : round(nodule_y[i] + 16) + y_shift]\n",
    "                        LS_patch = LS_scan[slice_idx, round(nodule_x[i] - 16) + x_shift : round(nodule_x[i] + 16) + x_shift,\\\n",
    "                                           round(nodule_y[i] - 16) + y_shift : round(nodule_y[i] + 16) + y_shift]\n",
    "\n",
    "                        if (GT_patch != 0).any():\n",
    "                            plt.imsave(os.path.abspath(save_path + '/' + set_being_prepared + '_GT' + '/' + SeriesInstanceUID + '_GT_' + \\\n",
    "                                                       '%03d' % slice_idx + '_' + '%03d' % nodule_x[i] + '_' + '%03d' % nodule_y[i] + '_' + '%02d' % (patch_idx) + '.png'), \\\n",
    "                                       GT_patch, vmin = 0.0, vmax = 1.0, cmap = 'gray', format = 'png')\n",
    "                            plt.imsave(os.path.abspath(save_path + '/' + set_being_prepared + '_PP' + '/' + SeriesInstanceUID + '_preprocessed_' \\\n",
    "                                                       + '%03d' % slice_idx + '_' + '%03d' % nodule_x[i] + '_' + '%03d' % nodule_y[i] + '_' + '%02d' % (patch_idx) + '.png'),\\\n",
    "                                       PP_patch, vmin = 0.0, vmax = 1.0, cmap = 'gray', format = 'png')\n",
    "                            plt.imsave(os.path.abspath(save_path + '/' + set_being_prepared + '/' + SeriesInstanceUID + '_segmented_' + \\\n",
    "                                                       '%03d' % slice_idx + '_' + '%03d' % nodule_x[i] + '_' + '%03d' % nodule_y[i] + '_' + '%02d' % (patch_idx) + '.png'), \\\n",
    "                                       LS_patch, vmin = 0.0, vmax = 1.0, cmap = 'gray', format = 'png')\n",
    "\n",
    "            # Generate negative patches that do not necessarily contain nodules.\n",
    "            num_positive_patches = len(glob(os.path.abspath(save_path + '/' + set_being_prepared + '_GT' + '/' + SeriesInstanceUID + '*.png')))\n",
    "            num_negative_patches = ceil(num_positive_patches * negative_patch_ratio)\n",
    "            \n",
    "            for negative_patch_idx in range(num_negative_patches):\n",
    "                # Randomly sample on the entire scan. Remember the scan shape is in the weird order of (z, y, x).\n",
    "                x_point = random.randint(16, np.shape(GT_scan)[1] - 16)\n",
    "                y_point = random.randint(16, np.shape(GT_scan)[2] - 16)\n",
    "                z_point = random.randint(16, np.shape(GT_scan)[0] - 16)\n",
    "                \n",
    "                GT_negative_patch = GT_scan[z_point, x_point - 16: x_point + 16, y_point - 16 : y_point + 16]\n",
    "                PP_negative_patch = PP_scan[z_point, x_point - 16: x_point + 16, y_point - 16 : y_point + 16]\n",
    "                LS_negative_patch = LS_scan[z_point, x_point - 16: x_point + 16, y_point - 16 : y_point + 16]\n",
    "                \n",
    "                plt.imsave(os.path.abspath(save_path + '/' + set_being_prepared + '_GT' + '/' + SeriesInstanceUID + '_GT_' + \\\n",
    "                                           'negative_' + '%02d' % negative_patch_idx + '.png'), \\\n",
    "                           GT_negative_patch, vmin = 0.0, vmax = 1.0, cmap = 'gray', format = 'png')\n",
    "                plt.imsave(os.path.abspath(save_path + '/' + set_being_prepared + '_PP' + '/' + SeriesInstanceUID + '_preprocessed_' \\\n",
    "                                           'negative_' + '%02d' % negative_patch_idx + '.png'), \\\n",
    "                           PP_negative_patch, vmin = 0.0, vmax = 1.0, cmap = 'gray', format = 'png')\n",
    "                plt.imsave(os.path.abspath(save_path + '/' + set_being_prepared + '/' + SeriesInstanceUID + '_segmented_' + \\\n",
    "                                           'negative_' + '%02d' % negative_patch_idx + '.png'), \\\n",
    "                           LS_negative_patch, vmin = 0.0, vmax = 1.0, cmap = 'gray', format = 'png')\n",
    "\n",
    "        except:\n",
    "            bad_scans.append(SeriesInstanceUID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of scans where the process above wasn't successful. The number should be (1 - number of segmented scans available so far).\n",
    "len(bad_scans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "lungpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
